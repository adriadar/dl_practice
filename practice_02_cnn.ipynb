{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr9vAeEQlRVG"
      },
      "source": [
        "# Введение в глубинное обучение, ФКН ВШЭ\n",
        "\n",
        "## Домашнее задание 2. Классификация изображений. Сверточные нейронные сети.\n",
        "\n",
        "### Общая информация\n",
        "\n",
        "Дата выдачи: 07.11.2021\n",
        "\n",
        "Мягкий дедлайн: 23:59MSK 05.12.2021\n",
        "\n",
        "Жесткий дедлайн: 23:59MSK 05.12.2021\n",
        "\n",
        "Оценка после штрафа после мягкого дедлайна вычисляется по формуле $M_{penalty} = M_{full} \\cdot 0.85^{t/1440}$, где $M_{full}$ — полная оценка за работу без учета штрафа, а $t$ — время в минутах, прошедшее после мягкого дедлайна (округление до двух цифр после запятой). Таким образом, спустя первые сутки после мягкого дедлайна вы не можете получить оценку выше 8.5, а если сдать перед самым жестким дедлайном, то ваш максимум — 5.22 балла.\n",
        "\n",
        "### Оценивание и штрафы\n",
        "\n",
        "Максимально допустимая оценка за работу — 10 баллов. Сдавать задание после указанного срока сдачи нельзя.\n",
        "\n",
        "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
        "\n",
        "Неэффективная реализация кода может негативно отразиться на оценке. Также оценка может быть снижена за плохо читаемый код и плохо оформленные графики. Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\n",
        "\n",
        "### О задании\n",
        "\n",
        "В этом задании потребуется обучить классификатор изображений. Будем работать с датасетом, название которого раскрывать не будем. Можете посмотреть самостоятельно на картинки, которые в есть датасете. В нём 200 классов и около 5 тысяч картинок на каждый класс. Классы пронумерованы, как нетрудно догадаться, от 0 до 199. Скачать датасет можно вот [тут](https://www.dropbox.com/s/33l8lp62rmvtx40/dataset.zip?dl=0).\n",
        "\n",
        "Структура датасета простая -- есть директории train/ и val/, в которых лежат обучающие и валидационные данные. В train/ и val/ лежат директориии, соответствующие классам изображений, в которых лежат, собственно, сами изображения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxX49gLclRVJ"
      },
      "source": [
        "## Задание 1. (Максимум 10 баллов + 5 бонусных баллов)\n",
        "\n",
        "__Необходимо выполнить любое из двух заданий (на выбор)__\n",
        "\n",
        "1) Добейтесь accuracy **на валидации не менее 0.44**. В этом задании **запрещено** пользоваться предобученными моделями и ресайзом картинок. \n",
        "\n",
        "2) Добейтесь accuracy **на валидации не менее 0.84**. В этом задании делать ресайз и использовать претрейн можно. \n",
        "\n",
        "Обязательно указывайте ссылки на чужой код, если вы его используете. Обязательно ссылайтесь на статьи / блогпосты / вопросы на stackoverflow / видосы от ютуберов-машинлернеров / курсы / подсказки от Дяди Васи и прочие дополнительные материалы, если вы их используете. \n",
        "\n",
        "Ваш код обязательно должен проходить все `assert`'ы ниже.\n",
        "\n",
        "Необходимо написать функции `train_one_epoch`, `train` и `predict` по шаблонам ниже (во многом повторяют примеры с семинаров). Обратите особое внимание на функцию `predict`: она должна возвращать список лоссов по всем объектам даталоадера, список предсказанных классов для каждого объекта из даталоалера и список настоящих классов для каждого объекта в даталоадере (и именно в таком порядке).\n",
        "\n",
        "__Использовать внешние данные для обучения строго запрещено в обоих заданиях. Также запрещено обучаться на валидационной выборке__.\n",
        "\n",
        "\n",
        "__Критерии оценки__: Оценка вычисляется по простой формуле: `min(10, 10 * Ваша accuracy / 0.44)` для первого задания и `min(10, 10 * (Ваша accuracy - 0.5) / 0.34)` для второго. Оценка округляется до десятых по арифметическим правилам. Если вы выполнили оба задания, то берется максимум из двух оценок.\n",
        "\n",
        "__Бонус__. Вы получаете 5 бонусных баллов если справляетесь с обоими заданиями на 10 баллов (итого 15 баллов). В противном случае выставляется максимальная из двух оценок и ваш бонус равен нулю.\n",
        "\n",
        "__Советы и указания__:\n",
        " - Наверняка вам потребуется много гуглить о классификации и о том, как заставить её работать. Это нормально, все гуглят. Но не забывайте, что нужно быть готовым за скатанный код отвечать :)\n",
        " - Используйте аугментации. Для этого пользуйтесь модулем `torchvision.transforms` или библиотекой [albumentations](https://github.com/albumentations-team/albumentations)\n",
        " - Можно обучать с нуля или файнтюнить (в зависимости от задания) модели из `torchvision`.\n",
        " - Рекомендуем написать вам сначала класс-датасет (или воспользоваться классом `ImageFolder`), который возвращает картинки и соответствующие им классы, а затем функции для трейна по шаблонам ниже. Однако делать это мы не заставляем. Если вам так неудобно, то можете писать код в удобном стиле. Однако учтите, что чрезмерное изменение нижеперечисленных шаблонов увеличит количество вопросов к вашему коду и повысит вероятность вызова на защиту :)\n",
        " - Валидируйте. Трекайте ошибки как можно раньше, чтобы не тратить время впустую.\n",
        " - Чтобы быстро отладить код, пробуйте обучаться на маленькой части датасета (скажем, 5-10 картинок просто чтобы убедиться что код запускается). Когда вы поняли, что смогли всё отдебажить, переходите обучению по всему датасету\n",
        " - На каждый запуск делайте ровно одно изменение в модели/аугментации/оптимайзере, чтобы понять, что и как влияет на результат.\n",
        " - Фиксируйте random seed.\n",
        " - Начинайте с простых моделей и постепенно переходите к сложным. Обучение лёгких моделей экономит много времени.\n",
        " - Ставьте расписание на learning rate. Уменьшайте его, когда лосс на валидации перестаёт убывать.\n",
        " - Советуем использовать GPU. Если у вас его нет, используйте google colab. Если вам неудобно его использовать на постоянной основе, напишите и отладьте весь код локально на CPU, а затем запустите уже написанный ноутбук в колабе. Авторское решение задания достигает требуемой точности в колабе за 45 минут обучения.\n",
        " \n",
        "Good luck & have fun! :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKcSNj4tlRVK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torchvision.datasets import ImageFolder\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llye3TAn9YOe"
      },
      "outputs": [],
      "source": [
        "!wget https://www.dropbox.com/s/33l8lp62rmvtx40/dataset.zip?dl=1 -O dataset.zip && unzip -q dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RytEDW0ylRVN"
      },
      "source": [
        "### Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GY52I-nnDguX"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def set_random_seed(seed):\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j95VXzpMVPjr"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import Normalize, ToTensor, Compose, ColorJitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4WwdzZtjC2q"
      },
      "outputs": [],
      "source": [
        "set_random_seed(101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEdDQtHdlRVO"
      },
      "outputs": [],
      "source": [
        "transform=Compose([ToTensor(), Normalize((0.5, 0.5, 0.5), (1, 1, 1))])\n",
        "train_transform = transform \n",
        "val_transform = transform\n",
        "\n",
        "train_dataset = ImageFolder(\"./dataset/dataset/train\", transform=train_transform)\n",
        "val_dataset = ImageFolder(\"./dataset/dataset/val\", transform=val_transform)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=256, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrg4Yj0VlRVP",
        "outputId": "2af273e7-3707-4129-d0da-69089610bd4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tests passed\n"
          ]
        }
      ],
      "source": [
        "# Just very simple sanity checks\n",
        "assert isinstance(train_dataset[0], tuple)\n",
        "assert len(train_dataset[0]) == 2\n",
        "assert isinstance(train_dataset[1][1], int)\n",
        "print(\"tests passed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RlSlmyjlRVP"
      },
      "source": [
        "### Вспомогательные функции, реализация модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYG2-Cq8lRVQ"
      },
      "outputs": [],
      "source": [
        "#тут использовался код с семинаров, evaluate ниже тоже с семинаров\n",
        "def train_one_epoch(model, data_loader, criterion, optimizer, device=\"cuda:0\", return_losses=False):\n",
        "    model = model.to(device).train()\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "    all_losses = []\n",
        "    total_predictions = np.array([])\n",
        "    total_labels = np.array([])\n",
        "    with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n",
        "        for images, labels in data_loader:\n",
        "            # Move Batch to GPU\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            predicted = model(images)\n",
        "            loss = criterion(predicted, labels)\n",
        "            # Update weights\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            # Update descirption for tqdm\n",
        "            accuracy = (predicted.argmax(1) == labels).float().mean()\n",
        "            prbar.set_description(\n",
        "                f\"Loss: {round(loss.item(), 4)} \"\n",
        "                f\"Accuracy: {round(accuracy.item(), 4)}\"\n",
        "            )\n",
        "            prbar.update(1)\n",
        "            total_loss += loss.item()\n",
        "            total_predictions = np.append(total_predictions, predicted.argmax(1).cpu().detach().numpy())\n",
        "            total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n",
        "            num_batches += 1\n",
        "            all_losses.append(loss.detach().item())\n",
        "    metrics = {\"loss\": total_loss / num_batches}\n",
        "    metrics.update({\"accuracy\": accuracy_score(total_predictions, total_labels)})\n",
        "    if return_losses:\n",
        "        return metrics, all_losses\n",
        "    else:\n",
        "        return metrics\n",
        "\n",
        "\n",
        "def predict(model, data_loader, criterion, device=\"cuda:0\"):\n",
        "    model = model.eval()\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "    predicted_classes = np.array([])\n",
        "    true_classes = np.array([])\n",
        "    losses = np.array([])\n",
        "    with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n",
        "        for images, labels in data_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            predicted = model(images)\n",
        "            loss = criterion(predicted, labels)\n",
        "            accuracy = (predicted.argmax(1) == labels).float().mean()\n",
        "            prbar.set_description(\n",
        "                f\"Loss: {round(loss.item(), 4)} \"\n",
        "                f\"Accuracy: {round(accuracy.item(), 4)}\"\n",
        "            )\n",
        "            prbar.update(1)\n",
        "            total_loss += loss.item()\n",
        "            losses = np.append(losses, loss.item())  \n",
        "            predicted_classes = np.append(predicted_classes, predicted.argmax(1).cpu().detach().numpy())\n",
        "            true_classes = np.append(true_classes, labels.cpu().detach().numpy())\n",
        "            num_batches += 1\n",
        "    metrics = {\"loss\": total_loss / num_batches}\n",
        "    metrics.update({\"accuracy\": accuracy_score(predicted_classes, true_classes)})\n",
        "\n",
        "    return losses, predicted_classes, true_classes\n",
        "\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader, criterion, optimizer, device=\"cuda:0\", epochs=10, scheduler=None):\n",
        "    all_train_losses = []\n",
        "    epoch_train_losses = []\n",
        "    epoch_eval_losses = []\n",
        "    for epoch in range(epochs):\n",
        "        # Train step\n",
        "        print(f\"Train Epoch: {epoch}\")\n",
        "        train_metrics, one_epoch_train_losses = train_one_epoch(\n",
        "            model=model,\n",
        "            data_loader=train_dataloader,\n",
        "            optimizer=optimizer,\n",
        "            return_losses=True,\n",
        "            criterion=criterion,\n",
        "        )\n",
        "        # Save Train losses\n",
        "        all_train_losses.extend(one_epoch_train_losses)\n",
        "        epoch_train_losses.append(train_metrics[\"loss\"])\n",
        "        # Eval step\n",
        "        print(f\"Validation Epoch: {epoch}\")\n",
        "        with torch.no_grad():\n",
        "            all_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxR3gfcilRVW"
      },
      "source": [
        "### Обучение модели, запуски экспериментов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zz1hND06J7kg",
        "outputId": "51fc1afa-78ca-4e80-f909-df741381334c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgLvW6cpIY_c"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet34, resnet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXFJ6oS8lRVX",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "set_random_seed(101)\n",
        "\n",
        "model = resnet34(pretrained=False)\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2)\n",
        "n_epochs = 7\n",
        "device = torch.device(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBEB3el4KSqU"
      },
      "outputs": [],
      "source": [
        "model = model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CesoOl6BlRVY"
      },
      "source": [
        "Простой тест на проверку правильности написанного кода"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_LB2jn6lRVY",
        "outputId": "cb650df7-4f0e-45d6-a6fb-0d83787bdf11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 6.7709 Accuracy: 0.0: 100%|██████████| 40/40 [00:11<00:00,  3.42it/s]\n",
            "tests passed\n"
          ]
        }
      ],
      "source": [
        "all_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)\n",
        "assert len(predicted_labels) == len(val_dataset)\n",
        "accuracy = accuracy_score(predicted_labels, true_labels)\n",
        "print(\"tests passed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS-LLiXUlRVY"
      },
      "source": [
        "Запустить обучение можно в ячейке ниже."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECIzZ_RYlRVZ",
        "outputId": "2e18e334-d85e-464e-8a81-851baf6f3533"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 0\n",
            "Loss: 4.0957 Accuracy: 0.1125: 100%|██████████| 391/391 [04:14<00:00,  1.54it/s]\n",
            "Validation Epoch: 0\n",
            "Loss: 3.3453 Accuracy: 0.3125: 100%|██████████| 40/40 [00:10<00:00,  3.64it/s]\n",
            "Train Epoch: 1\n",
            "Loss: 3.397 Accuracy: 0.2125: 100%|██████████| 391/391 [04:12<00:00,  1.55it/s]\n",
            "Validation Epoch: 1\n",
            "Loss: 3.9631 Accuracy: 0.0625: 100%|██████████| 40/40 [00:11<00:00,  3.61it/s]\n",
            "Train Epoch: 2\n",
            "Loss: 2.9395 Accuracy: 0.3: 100%|██████████| 391/391 [04:13<00:00,  1.54it/s]\n",
            "Validation Epoch: 2\n",
            "Loss: 2.7836 Accuracy: 0.1875: 100%|██████████| 40/40 [00:11<00:00,  3.60it/s]\n",
            "Train Epoch: 3\n",
            "Loss: 2.9651 Accuracy: 0.3063: 100%|██████████| 391/391 [04:12<00:00,  1.55it/s]\n",
            "Validation Epoch: 3\n",
            "Loss: 2.6434 Accuracy: 0.3125: 100%|██████████| 40/40 [00:11<00:00,  3.57it/s]\n",
            "Train Epoch: 4\n",
            "Loss: 2.675 Accuracy: 0.35: 100%|██████████| 391/391 [04:14<00:00,  1.54it/s]\n",
            "Validation Epoch: 4\n",
            "Loss: 2.116 Accuracy: 0.4375: 100%|██████████| 40/40 [00:11<00:00,  3.55it/s]\n",
            "Train Epoch: 5\n",
            "Loss: 2.3875 Accuracy: 0.4188: 100%|██████████| 391/391 [04:13<00:00,  1.54it/s]\n",
            "Validation Epoch: 5\n",
            "Loss: 2.3139 Accuracy: 0.5625: 100%|██████████| 40/40 [00:11<00:00,  3.55it/s]\n",
            "Train Epoch: 6\n",
            "Loss: 2.0528 Accuracy: 0.5063: 100%|██████████| 391/391 [04:13<00:00,  1.54it/s]\n",
            "Validation Epoch: 6\n",
            "Loss: 1.7183 Accuracy: 0.6875: 100%|██████████| 40/40 [00:11<00:00,  3.56it/s]\n"
          ]
        }
      ],
      "source": [
        "train(model, train_dataloader, val_dataloader, criterion, optimizer, device, n_epochs, scheduler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImVW8_EXlRVZ"
      },
      "source": [
        "### Проверка полученной accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmR-elhJlRVZ"
      },
      "source": [
        "После всех экспериментов которые вы проделали, выберите лучшую из своих моделей, реализуйте и запустите функцию `evaluate`. Эта функция должна брать на вход модель и даталоадер с валидационными данными и возврашать accuracy, посчитанную на этом датасете."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9LvhxhvPoRz"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, eval_dataloader, criterion, device=\"cuda:0\"):\n",
        "    cumulative_loss = 0\n",
        "    acc = 0\n",
        "    model = model.to(device).eval()\n",
        "    with torch.no_grad():\n",
        "        for idx, (images, labels) in enumerate(eval_dataloader): \n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            preds = model(images)\n",
        "            acc += (preds.argmax(1) == labels).float().mean()\n",
        "    print(\"accuracy = {:.4f}\".format(acc / idx))\n",
        "    return acc / idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_r72aVmS4OL",
        "outputId": "6c0408e7-1075-44af-a8be-caccbeadbda8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy = 0.3633\n",
            "tensor(0.3633, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "acc = evaluate(model, val_dataloader, criterion)\n",
        "print(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TGH0EFalRVb",
        "outputId": "d8fa5f6c-c26e-4553-8423-2020dcfc6e18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.7183 Accuracy: 0.6875: 100%|██████████| 40/40 [00:11<00:00,  3.60it/s]\n",
            "0.3462\n",
            "Оценка за 1 задание составит 7.87 баллов.\n"
          ]
        }
      ],
      "source": [
        "all_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)\n",
        "assert len(predicted_labels) == len(val_dataset)\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(accuracy)\n",
        "print(f'Оценка за 1 задание составит {np.clip(10 * accuracy / 0.44, 0, 10):.2f} баллов.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT8vfPSolRVb"
      },
      "source": [
        "## Задание 2 (0 баллов, но при невыполнении максимум за все задание — 0 баллов)\n",
        "\n",
        "Напишите небольшой отчет о том, как вы добились полученного качества: какие средства использовали и какие эксперименты проводили. Подробно расскажите об архитектурах и значениях гиперпараметров, а также какие метрики на тесте они показывали. Чтобы отчет был зачтен, необходимо привести хотя бы 3 эксперимента."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXAs_VLD5LK_"
      },
      "source": [
        "Я решала первую задачу, используя готовые не предобученные сети.\n",
        "\n",
        "## Эксперимент 1 (итоговый):\n",
        "Использовался только Normalize((0.5, 0.5, 0.5), (1, 1, 1))\n",
        "\n",
        "batch size : 256\n",
        "\n",
        "Архитектура: resnet34, без предтрейна\n",
        "\n",
        "Оптимизатор: Adam, lr = 1e-3\n",
        "\n",
        "Функция потерь: CrossEntropyLoss\n",
        "\n",
        "scheduler: ReduceLROnPlateau\n",
        "\n",
        "Кол-во эпох: 7\n",
        "\n",
        "accuracy = 0.3462\n",
        "\n",
        "Если увеличить число эпох сеть сильно переобучалась в данном случае.\n",
        "\n",
        "## Эксперимент 2:\n",
        "\n",
        "Использовался только Normalize((0.5, 0.5, 0.5), (1, 1, 1))\n",
        "\n",
        "batch size : 256\n",
        "\n",
        "Архитектура: resnet18, без предтрейна\n",
        "\n",
        "Оптимизатор: Adam, lr = 3e-3\n",
        "\n",
        "Функция потерь: CrossEntropyLoss\n",
        "\n",
        "scheduler: ReduceLROnPlateau\n",
        "\n",
        "Кол-во эпох: 7\n",
        "\n",
        "accuracy : 0.3278\n",
        "\n",
        "## Эксперимент 3:\n",
        "Normalize((0.5, 0.5, 0.5), (1, 1, 1)), ColorJitter(brightness=.3, hue=.2)\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "Архитектура: resnet18, без предтрейна\n",
        "\n",
        "Оптимизатор: Adam, lr = 3e-3\n",
        "\n",
        "Функция потерь: CrossEntropyLoss\n",
        "\n",
        "scheduler: не используется\n",
        "\n",
        "Кол-во эпох: 11\n",
        "\n",
        "accuracy: 0.2437\n",
        "\n",
        "Самый неудачный эксперимент. Причем увеличить число эпох особо не помогло, модель только начала переобучаться."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "homework-02-cnn-Shagalkina.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "max_cell_id": 35
  },
  "nbformat": 4,
  "nbformat_minor": 0
}